{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Classification with Deep Convolutional Neural Networks\n",
    "\n",
    "4824-imagenet-classification-with-deep-convolutional-neural-Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Architecture\n",
    "\n",
    "다음은 \"4824-imagenet-classification-with-deep-convolutional-neural-Networks\" 논문의 일부이다.\n",
    "\n",
    "### 3.5 Overall Architecture\n",
    "\n",
    "Now we are ready to describe the overall architecture of our CNN. As depicted in Figure 2, the net contains eight layers with weights; the first five are convolutional and the remaining three are fullyconnected. The output of the last fully-connected layer is fed to a 1000-way softmax which produces a distribution over the 1000 class labels. Our network maximizes the multinomial logistic regression objective, which is equivalent to maximizing the average across training cases of the log-probability of the correct label under the prediction distribution.\n",
    "\n",
    "The kernels of the second, fourth, and fifth convolutional layers are connected only to those kernel maps in the previous layer which reside on the same GPU (see Figure 2). The kernels of the third convolutional layer are connected to all kernel maps in the second layer. The neurons in the fully-connected layers are connected to all neurons in the previous layer. Response-normalization layers follow the first and second convolutional layers. Max-pooling layers, of the kind described in Section 3.4, follow both response-normalization layers as well as the fifth convolutional layer. The ReLU non-linearity is applied to the output of every convolutional and fully-connected layer.\n",
    "\n",
    "The first convolutional layer filters the 224×224×3 input image with 96 kernels of size 11×11×3 with a stride of 4 pixels (this is the distance between the receptive field centers of neighboring neurons in a kernel map). The second convolutional layer takes as input the (response-normalized and pooled) output of the first convolutional layer and filters it with 256 kernels of size 5 × 5 × 48. The third, fourth, and fifth convolutional layers are connected to one another without any intervening pooling or normalization layers. The third convolutional layer has 384 kernels of size 3 × 3 × 256 connected to the (normalized, pooled) outputs of the second convolutional layer. The fourth convolutional layer has 384 kernels of size 3 × 3 × 192 , and the fifth convolutional layer has 256 kernels of size 3 × 3 × 192. The fully-connected layers have 4096 neurons each.\n",
    "\n",
    "![Figure 2](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99FEB93C5C80B5192E \"AlexNet의 구조도\")\n",
    "\n",
    "Figure 2: An illustration of the architecture of our CNN, explicitly showing the delineation of responsibilities between the two GPUs. One GPU runs the layer-parts at the top of the figure while the other runs the layer-parts at the bottom. The GPUs communicate only at certain layers. The network’s input is 150,528-dimensional, and the number of neurons in the network’s remaining layers is given by 253,440–186,624–64,896–64,896–43,264–4096–4096–1000.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 내용을 토대로 AlexNet의 구성을 정리하면 다음과 같다.\n",
    "\n",
    "* 총 8개의 층으로 구성\n",
    "    * x5 Convolutional layers\n",
    "    * x3 Fully-Connected layers\n",
    "* 출력은 마지막층에 대한 1000-way softmax 분포.\n",
    "\n",
    "\n",
    "그 외 참고: [url](https://engmrk.com/alexnet-implementation-using-keras/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Local Response Normalization\n",
    "\n",
    "Keras에는 Local Response Normalization 명령이 없어졌다고 한다. [이 곳](https://datascienceschool.net/view-notebook/d19e803640094f76b93f11b850b920a4/)에 구현된 LRN명령을 가져와 사용한다.\n",
    "\n",
    "참고:\n",
    "* [Difference between Local Response Normalization and Batch Normalization](https://towardsdatascience.com/difference-between-local-response-normalization-and-batch-normalization-272308c034ac)\n",
    "* [AlexNet - Data Science School](https://datascienceschool.net/view-notebook/d19e803640094f76b93f11b850b920a4/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "class LocalResponseNormalization(Layer):\n",
    "\n",
    "    def __init__(self, n=5, alpha=1e-4, beta=0.75, k=2, **kwargs):\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.k = k\n",
    "        super(LocalResponseNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.shape = input_shape\n",
    "        super(LocalResponseNormalization, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        _, r, c, f = self.shape \n",
    "        squared = backend.square(x)\n",
    "        pooled = backend.pool2d(squared, (self.n, self.n), strides=(1,1), padding=\"same\", pool_mode='avg')\n",
    "        summed = backend.sum(pooled, axis=3, keepdims=True)\n",
    "        averaged = self.alpha * backend.repeat_elements(summed, f, axis=3)\n",
    "        denom = backend.pow(self.k + averaged, self.beta)\n",
    "        return x / denom \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## AlexNet using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first convolutional layer\n",
    "\n",
    "@ 3.5 Overall Architecture\n",
    "> The first convolutional layer filters the 224×224×3 input image with 96 kernels of size 11×11×3 with a stride of 4 pixels (this is the distance between the receptive field centers of neighboring neurons in a kernel map).\n",
    "\n",
    "정리:\n",
    "* input_shape = (224, 224, 3)\n",
    "* kernel_size = (11, 11, 3)\n",
    "* kernels = 96\n",
    "* strides = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first convolutional layer\n",
    "model.add(Conv2D(\n",
    "    input_shape=(224,224,3),\n",
    "    kernel_size=(11,11),\n",
    "    filters=96,\n",
    "    strides=(4,4),\n",
    "    padding='valid',\n",
    "    activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The second convolutional layer\n",
    "\n",
    "@ 3.5 Overall Architecture\n",
    "> The second convolutional layer takes as input the (response-normalized and pooled) output of the first convolutional layer and filters it with 256 kernels of size 5 × 5 × 48.\n",
    "\n",
    "정리:\n",
    "* input_shape = response-normalized, pooled of 1st layer\n",
    "* kernel_size = (5, 5, 48)\n",
    "* kernels = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second convolutional layer\n",
    "model.add(LocalResponseNormalization())\n",
    "model.add(MaxPooling2D(\n",
    "    pool_size=(5,5),\n",
    "    strides=(1,1),\n",
    "    padding='valid'))\n",
    "model.add(Conv2D(\n",
    "    filters=256,\n",
    "    kernel_size=(5,5),\n",
    "    padding='valid',\n",
    "    activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The third convolutional layer\n",
    "\n",
    "@ 3.5 Overall Architecture\n",
    "> The third, fourth, and fifth convolutional layers are connected to one another without any intervening pooling or normalization layers. The third convolutional layer has 384 kernels of size 3 × 3 × 256 connected to the (normalized, pooled) outputs of the second convolutional layer.\n",
    "\n",
    "정리:\n",
    "* input_shape = response-normalized, pooled of 2nd layer\n",
    "* kernel_size = (3, 3, 256)\n",
    "* kernels = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The third convolutional layer\n",
    "model.add(LocalResponseNormalization())\n",
    "model.add(MaxPooling2D(\n",
    "    pool_size=(3,3),\n",
    "    strides=(1,1),\n",
    "    padding='valid'))\n",
    "model.add(Conv2D(\n",
    "    filters=384,\n",
    "    kernel_size=(3,3),\n",
    "    padding='valid',\n",
    "    activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fourth convolutional layer\n",
    "\n",
    "@ 3.5 Overall Architecture\n",
    "> The fourth convolutional layer has 384 kernels of size 3 × 3 × 192 \n",
    "\n",
    "정리:\n",
    "* kernel_size = (3, 3, 192)\n",
    "* kernels = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fourth convolutional layer\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=384,\n",
    "        kernel_size=(3,3),\n",
    "        padding='valid',\n",
    "        activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fifth convolutional layer\n",
    "\n",
    "@ 3.5 Overall Architecture\n",
    "> ... , and the fifth convolutional layer has 256 kernels of size 3 × 3 × 192.\n",
    "\n",
    "정리:\n",
    "* kernel_size = (3, 3, 192)\n",
    "* kernels = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fifth convolutional layer\n",
    "model.add(Conv2D(\n",
    "    filters=256,\n",
    "    kernel_size=(3,3),\n",
    "    padding='valid',\n",
    "    activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect between Convolutional layers and Fully-Connected layers\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-connected layers\n",
    "\n",
    "@ 3.5 Overall Architecture\n",
    ">  The fully-connected layers have 4096 neurons each.\n",
    "\n",
    "@ 4.2 Dropout\n",
    "> We use dropout in the first two fully-connected layers of Figure 2. Without dropout, our network exhibits substantial overfitting. Dropout roughly doubles the number of iterations required to converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6th Layer: Fully-Connected\n",
    "model.add(Dense(units=4096, activation='relu'))\n",
    "model.add(Dropout(rate=0.4))\n",
    "# 7th Layer: Fully-Connected\n",
    "model.add(Dense(units=4096, activation='relu'))\n",
    "model.add(Dropout(rate=0.4))\n",
    "# 8th Layer: Fully-Connected\n",
    "model.add(Dense(units=1000, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Layer\n",
    "model.add(Dense(units=1000, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n________________________________________________________________________\nLayer (type)                        Output Shape             Param #    \n========================================================================\nconv2d (Conv2D)                     (None, 54, 54, 96)       34944      \n________________________________________________________________________\nlocal_response_normalization (Local (None, 54, 54, 96)       0          \n________________________________________________________________________\nmax_pooling2d (MaxPooling2D)        (None, 50, 50, 96)       0          \n________________________________________________________________________\nconv2d_1 (Conv2D)                   (None, 46, 46, 256)      614656     \n________________________________________________________________________\nlocal_response_normalization_1 (Loc (None, 46, 46, 256)      0          \n________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)      (None, 44, 44, 256)      0          \n________________________________________________________________________\nconv2d_2 (Conv2D)                   (None, 42, 42, 384)      885120     \n________________________________________________________________________\nconv2d_3 (Conv2D)                   (None, 40, 40, 384)      1327488    \n________________________________________________________________________\nconv2d_4 (Conv2D)                   (None, 38, 38, 256)      884992     \n________________________________________________________________________\nflatten (Flatten)                   (None, 369664)           0          \n________________________________________________________________________\ndense (Dense)                       (None, 4096)             1514147840 \n________________________________________________________________________\ndropout (Dropout)                   (None, 4096)             0          \n________________________________________________________________________\ndense_1 (Dense)                     (None, 4096)             16781312   \n________________________________________________________________________\ndropout_1 (Dropout)                 (None, 4096)             0          \n________________________________________________________________________\ndense_2 (Dense)                     (None, 1000)             4097000    \n________________________________________________________________________\ndense_3 (Dense)                     (None, 1000)             1001000    \n========================================================================\nTotal params: 1,539,774,352\nTrainable params: 1,539,774,352\nNon-trainable params: 0\n________________________________________________________________________\nWARNING:tensorflow:From C:\\Users\\KDJ\\anaconda3\\envs\\DG_AI_System\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: ./models/AlexNet.no-division.model\\assets\n"
    }
   ],
   "source": [
    "# End of layers\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "model.summary(line_length=72, positions=[.5, .86, 1., 1.])\n",
    "model.save('./models/AlexNet.no-division.model')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}